{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224bf43e-d081-4cef-86b9-e29a40f5bee6",
   "metadata": {},
   "source": [
    "# Project Outline: Predicting Mobile Plans\n",
    "\n",
    "## Objective\n",
    "The objective of this project is to develop a machine learning model that analyzes user behavior and recommends one of two mobile plans offered by Megaline:\n",
    "1. **Smart Plan**\n",
    "2. **Ultra Plan**\n",
    "\n",
    "The model's target accuracy is **0.75** on unseen data.\n",
    "\n",
    "## Data Overview\n",
    "The dataset contains monthly behavior information for Megaline subscribers, including:\n",
    "- **calls**: Number of calls made.\n",
    "- **minutes**: Total call duration in minutes.\n",
    "- **messages**: Number of text messages sent.\n",
    "- **mb_used**: Internet traffic used in megabytes.\n",
    "- **is_ultra**: Target variable indicating the current plan (1 = Ultra, 0 = Smart).\n",
    "\n",
    "## Steps Taken\n",
    "1. **Data Inspection and Cleaning**:\n",
    "   - Explored the dataset for missing values, duplicates, and outliers.\n",
    "   - Cleaned the data to ensure it is ready for modeling.\n",
    "2. **Data Splitting**:\n",
    "   - Divided the dataset into training, validation, and test sets (60/20/20 split) with stratification to maintain class balance.\n",
    "3. **Model Training and Evaluation**:\n",
    "   - Trained and evaluated three models:\n",
    "     - Logistic Regression\n",
    "     - Decision Tree\n",
    "     - Random Forest\n",
    "   - Performed hyperparameter tuning on the best-performing model (Random Forest) using GridSearchCV.\n",
    "4. **Addressing Class Imbalance**:\n",
    "   - Applied class weighting to improve the model's ability to predict the minority class (Ultra Plan).\n",
    "5. **Model Testing**:\n",
    "   - Evaluated the final model on the test set to ensure robust performance.\n",
    "\n",
    "## Deliverables\n",
    "1. A well-documented machine learning model capable of accurately recommending mobile plans.\n",
    "2. Performance metrics, including accuracy, precision, recall, F1-score, and confusion matrix for both Smart and Ultra plans.\n",
    "3. Recommendations for potential improvements and future work.\n",
    "\n",
    "## Tools and Libraries Used\n",
    "- **Python**: For data processing, model training, and evaluation.\n",
    "- **Libraries**:\n",
    "  - `pandas` and `numpy` for data manipulation.\n",
    "  - `scikit-learn` for machine learning models and evaluation metrics.\n",
    "\n",
    "## Project Goal\n",
    "By successfully completing this project, Megaline will have a reliable recommendation system that ensures users are assigned the most suitable plan, improving customer satisfaction and operational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017a9fba-48f5-4fba-a417-d1a63a9fecba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "First 5 Rows of the Dataset:\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Missing Values:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/mattbaglietto/megaline_mobile/users_behavior.csv'  # Updated path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst 5 Rows of the Dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2031e0-566b-4b81-999d-4ce9f307a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution (is_ultra):\n",
      "is_ultra\n",
      "0    2211\n",
      "1     774\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data Cleaning Complete. Cleaned data saved to: /Users/mattbaglietto/megaline_mobile/cleaned_users_behavior.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/mattbaglietto/megaline_mobile/users_behavior.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Streamlined Data Cleaning\n",
    "def clean_data(df):\n",
    "    # Remove rows with missing values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Remove outliers using IQR for relevant columns\n",
    "    def remove_outliers(series):\n",
    "        Q1, Q3 = series.quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        return series[(series >= lower_bound) & (series <= upper_bound)]\n",
    "\n",
    "    for col in ['calls', 'minutes', 'messages', 'mb_used']:\n",
    "        df = df[df[col].isin(remove_outliers(df[col]))]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply cleaning function\n",
    "data_cleaned = clean_data(data)\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass Distribution (is_ultra):\")\n",
    "print(data_cleaned['is_ultra'].value_counts())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = '/Users/mattbaglietto/megaline_mobile/cleaned_users_behavior.csv'\n",
    "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"\\nData Cleaning Complete. Cleaned data saved to:\", cleaned_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e1ac35-ce57-404f-ac45-39e1eadc4ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (1791, 4)\n",
      "Validation Set: (597, 4)\n",
      "Test Set: (597, 4)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned dataset\n",
    "cleaned_file_path = '/Users/mattbaglietto/megaline_mobile/cleaned_users_behavior.csv'\n",
    "data = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(columns=['is_ultra'])  # Features\n",
    "y = data['is_ultra']  # Target\n",
    "\n",
    "# Split the data into train, validation, and test sets (60%, 20%, 20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Output the sizes of each set\n",
    "print(f\"Training Set: {X_train.shape}\")\n",
    "print(f\"Validation Set: {X_val.shape}\")\n",
    "print(f\"Test Set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4533a7a-f872-405e-aaa2-2f4b35449333",
   "metadata": {},
   "source": [
    "# Data Splitting Summary\n",
    "\n",
    "## Overview\n",
    "The cleaned dataset has been split into three subsets to facilitate model training, validation, and testing. This ensures a systematic approach to building and evaluating the machine learning model.\n",
    "\n",
    "## Splitting Results\n",
    "- **Training Set**: 1791 samples with 4 features each.\n",
    "- **Validation Set**: 597 samples with 4 features each.\n",
    "- **Test Set**: 597 samples with 4 features each.\n",
    "\n",
    "## Splitting Ratios\n",
    "- **Training Set (60%)**: Used to train the model.\n",
    "- **Validation Set (20%)**: Used to tune hyperparameters and prevent overfitting.\n",
    "- **Test Set (20%)**: Used for evaluating the final performance of the model.\n",
    "\n",
    "## Stratification\n",
    "Stratification was used during splitting to ensure that the class distribution of the target variable (`is_ultra`) is consistent across all subsets.\n",
    "\n",
    "## Notes\n",
    "- The cleaned dataset (`cleaned_behavior.csv`) was used as the source file.\n",
    "- The random seed ensures reproducibility of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d872fbc-f147-492b-a63b-38f104bcc671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy: 0.7420\n",
      "Decision Tree Validation Accuracy: 0.7069\n",
      "Random Forest Validation Accuracy: 0.8057\n",
      "\n",
      "Model Performance:\n",
      "Logistic Regression: 0.7420\n",
      "Decision Tree: 0.7069\n",
      "Random Forest: 0.8057\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel Performance:\")\n",
    "for model, acc in results.items():\n",
    "    print(f\"{model}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6456d93-703f-443d-80a2-a01865708254",
   "metadata": {},
   "source": [
    "# Model Building and Evaluation\n",
    "\n",
    "## Objective\n",
    "To identify the best-performing classification model for predicting the correct mobile plan (Smart or Ultra). The target is to achieve a minimum accuracy of **0.75** on the validation dataset.\n",
    "\n",
    "## Approach\n",
    "1. **Selected Models**:\n",
    "   - Logistic Regression\n",
    "   - Decision Tree Classifier\n",
    "   - Random Forest Classifier\n",
    "2. **Datasets Used**:\n",
    "   - **Training Set**: Used to train the models.\n",
    "   - **Validation Set**: Used to evaluate and compare the models' performance.\n",
    "3. **Evaluation Metric**:\n",
    "   - **Accuracy Score**: The proportion of correct predictions on the validation dataset.\n",
    "\n",
    "## Analysis\n",
    "- **Best Model**: Random Forest with a validation accuracy of **0.8057**.\n",
    "- Random Forest exceeded the target accuracy of **0.75**, making it the most promising candidate for further tuning and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46f3e68b-8df6-4ca3-8c01-760c76584f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Validation Accuracy: 0.8056951423785593\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and their validation accuracy\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb84dfdd-7361-45cf-8246-33316d68577d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Random Forest\n",
    "\n",
    "## Objective\n",
    "To optimize the Random Forest model by fine-tuning its hyperparameters, maximizing validation accuracy, and ensuring the best possible performance.\n",
    "\n",
    "## Approach\n",
    "1. **Hyperparameters Tuned**:\n",
    "   - `n_estimators`: Number of trees in the forest.\n",
    "   - `max_depth`: Maximum depth of each tree.\n",
    "   - `min_samples_split`: Minimum number of samples required to split a node.\n",
    "   - `min_samples_leaf`: Minimum number of samples required at a leaf node.\n",
    "\n",
    "2. **Methodology**:\n",
    "   - **Grid Search**: Systematically evaluates combinations of hyperparameters using a predefined grid.\n",
    "   - **Cross-Validation**: Uses 3-fold cross-validation to ensure robust evaluation of each parameter combination.\n",
    "\n",
    "3. **Evaluation Metric**:\n",
    "   - Accuracy Score: Maximizes validation accuracy during the grid search.\n",
    "\n",
    "## Parameter Grid\n",
    "| Hyperparameter       | Values Tested                          |\n",
    "|----------------------|-----------------------------------------|\n",
    "| `n_estimators`       | [50, 100, 200]                         |\n",
    "| `max_depth`          | [None, 10, 20, 30]                     |\n",
    "| `min_samples_split`  | [2, 5, 10]                             |\n",
    "| `min_samples_leaf`   | [1, 2, 4]                              |\n",
    "\n",
    "## Analysis\n",
    "The best validation accuracy achieved during hyperparameter tuning was **0.8057**, using the above parameters. This is consistent with the baseline Random Forest performance but demonstrates the impact of careful tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e45f5d-9b7a-4cd0-875f-723256216cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.7705\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85       442\n",
      "           1       0.59      0.38      0.46       155\n",
      "\n",
      "    accuracy                           0.77       597\n",
      "   macro avg       0.70      0.64      0.66       597\n",
      "weighted avg       0.75      0.77      0.75       597\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[401  41]\n",
      " [ 96  59]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the final model using the best parameters\n",
    "final_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "final_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = final_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403aa255-0a84-4508-a4fa-7554e4e439e4",
   "metadata": {},
   "source": [
    "# Final Model Evaluation\n",
    "\n",
    "## Objective\n",
    "Evaluate the final Random Forest model on the **Test Set** using the best hyperparameters identified during tuning. This step assesses the model's ability to generalize to unseen data.\n",
    "\n",
    "## Analysis\n",
    "- The model performs well in predicting **Smart Plan (Class 0)**, with high precision and recall.\n",
    "- **Ultra Plan (Class 1)** predictions are less accurate, with lower recall (38%), indicating difficulty in identifying this class correctly.\n",
    "- The overall accuracy of 77.05% indicates the model generalizes well but struggles with imbalanced class predictions.\n",
    "\n",
    "## Key Insights\n",
    "- The imbalance in the dataset (fewer Ultra Plan users) may have impacted the model's ability to predict Class 1 accurately.\n",
    "- Precision for **Ultra Plan (Class 1)** is moderate, but recall is significantly lower, suggesting the model misses many actual Ultra users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce40ca62-a718-401c-b63b-8569e3008ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy (Balanced): 0.7588\n",
      "\n",
      "Classification Report (Balanced):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       442\n",
      "           1       0.54      0.50      0.52       155\n",
      "\n",
      "    accuracy                           0.76       597\n",
      "   macro avg       0.68      0.67      0.68       597\n",
      "weighted avg       0.75      0.76      0.76       597\n",
      "\n",
      "\n",
      "Confusion Matrix (Balanced):\n",
      "[[376  66]\n",
      " [ 78  77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the Random Forest model with class weights\n",
    "rf_balanced = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight=\"balanced\",  # Automatically adjusts weights inversely proportional to class frequencies\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred_balanced = rf_balanced.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy_balanced = accuracy_score(y_test, y_test_pred_balanced)\n",
    "print(f\"Test Set Accuracy (Balanced): {test_accuracy_balanced:.4f}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nClassification Report (Balanced):\")\n",
    "print(classification_report(y_test, y_test_pred_balanced))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Balanced):\")\n",
    "print(confusion_matrix(y_test, y_test_pred_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbcab9-2e40-4f40-bbb1-2919c5b188ab",
   "metadata": {},
   "source": [
    "# Addressing Class Imbalance\n",
    "\n",
    "## Objective\n",
    "To improve the model's performance, particularly for the minority class (**Ultra Plan - Class 1**), by addressing class imbalance using **class weights**.\n",
    "\n",
    "## Methodology\n",
    "The `RandomForestClassifier` was configured with the parameter `class_weight=\"balanced\"`, which automatically adjusts class weights inversely proportional to their frequencies in the dataset. This ensures that the minority class receives more importance during training.\n",
    "\n",
    "## Analysis\n",
    "- **Class 0 (Smart)**: High precision and recall are maintained, indicating the model continues to predict this majority class effectively.\n",
    "- **Class 1 (Ultra)**: Recall improved to **0.50**, showing the model correctly identifies more Ultra users compared to the imbalanced model (**0.38 recall before**).\n",
    "- **Tradeoff**: Accuracy decreased slightly, but the performance on the minority class has improved, demonstrating better balance in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4922b-7698-4634-bbb6-6222f2c6bc35",
   "metadata": {},
   "source": [
    "# Project Conclusion: Predicting Mobile Plans\n",
    "\n",
    "## Objective\n",
    "The goal of this project was to develop a machine learning model to recommend one of two mobile plans (Smart or Ultra) based on user behavior, achieving a minimum accuracy of 0.75 on unseen data.\n",
    "\n",
    "## Approach\n",
    "1. **Data Cleaning**:\n",
    "   - Addressed missing values, duplicates, and outliers to prepare the dataset for modeling.\n",
    "2. **Data Splitting**:\n",
    "   - Divided the data into training, validation, and test sets using a 60/20/20 split with stratification.\n",
    "3. **Model Development**:\n",
    "   - Evaluated Logistic Regression, Decision Tree, and Random Forest models.\n",
    "   - Performed hyperparameter tuning on the Random Forest model to maximize validation accuracy.\n",
    "4. **Addressing Class Imbalance**:\n",
    "   - Applied class weighting to improve performance for the minority class (Ultra Plan).\n",
    "\n",
    "## Results\n",
    "- **Best Model**: Random Forest\n",
    "- **Test Set Performance (Balanced Model)**:\n",
    "  - **Accuracy**: 0.7588\n",
    "  - **Class 0 (Smart Plan)**:\n",
    "    - Precision: 0.83, Recall: 0.85, F1-Score: 0.84\n",
    "  - **Class 1 (Ultra Plan)**:\n",
    "    - Precision: 0.54, Recall: 0.50, F1-Score: 0.52\n",
    "  - **Macro Avg F1-Score**: 0.68\n",
    "  - **Weighted Avg F1-Score**: 0.76\n",
    "- **Confusion Matrix**:\n",
    "  |               | Predicted: Smart (0) | Predicted: Ultra (1) |\n",
    "  |---------------|-----------------------|-----------------------|\n",
    "  | **Actual: Smart (0)** | 376                   | 66                    |\n",
    "  | **Actual: Ultra (1)** | 78                    | 77                    |\n",
    "\n",
    "## Analysis\n",
    "The final model achieves balanced performance, correctly identifying a significant proportion of Ultra users while maintaining high precision and recall for Smart users. Adjusting for class imbalance improved recall for the Ultra Plan (from 0.38 to 0.50), enhancing the model's overall utility.\n",
    "\n",
    "## Conclusion\n",
    "The project successfully met the target accuracy of 0.75, and the Random Forest model provides a reliable recommendation system for mobile plans. \n",
    "\n",
    "This model is ready for deployment, and its robust performance can support Megaline in recommending optimal plans to their customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
